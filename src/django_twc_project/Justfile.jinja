set dotenv-load := true

export DATABASE_URL := env_var_or_default('DATABASE_URL', 'postgres://postgres:postgres@db:5432/postgres')

@_default:
    just --list

# ----------------------------------------------------------------------
# DEPENDENCIES
# ----------------------------------------------------------------------

bootstrap:
    python -m pip install --upgrade pip uv
    @just install

lock *ARGS:
    python -m uv pip compile {% raw %}{{ ARGS }}{% endraw %} --generate-hashes requirements.in --output-file requirements.txt

install *ARGS:
    python -m uv pip install --upgrade -r requirements.txt

upgrade:
    @just lock --upgrade

pup:
    python -m pip install --upgrade pip uv

update:
    @just pup
    @just upgrade
    @just install

# ----------------------------------------------------------------------
# TESTING/TYPES
# ----------------------------------------------------------------------

test *ARGS:
    just command python -m pytest {% raw %}{{ ARGS }}{% endraw %}

coverage:
    rm -rf htmlcov
    just command python -m coverage run -m pytest && python -m coverage html --skip-covered --skip-empty

types:
    just command python -m mypy .

# ----------------------------------------------------------------------
# DJANGO
# ----------------------------------------------------------------------

@manage *COMMAND:
    just command python -m manage {% raw %}{{ COMMAND }}{% endraw %}

alias mm := makemigrations

makemigrations *APPS:
    @just manage makemigrations {% raw %}{{ APPS }}{% endraw %}

migrate *ARGS:
    @just manage migrate {% raw %}{{ ARGS }}{% endraw %}

shell-plus:
    @just manage shell_plus

createsuperuser USERNAME="admin" EMAIL="" PASSWORD="admin":
    docker compose run --rm --no-deps app /bin/bash -c 'echo "from django.contrib.auth import get_user_model; User = get_user_model(); User.objects.create_superuser('"'"'{% raw %}{{ USERNAME }}{% endraw %}'"'"', '"'"'{% raw %}{{ EMAIL }}{% endraw %}'"'"', '"'"'{% raw %}{{ PASSWORD }}{% endraw %}'"'"') if not User.objects.filter(username='"'"'{% raw %}{{ USERNAME }}{% endraw %}'"'"').exists() else None" | python manage.py shell'

resetuserpassword USERNAME="admin" PASSWORD="admin":
    docker compose run --rm --no-deps app /bin/bash -c 'echo "from django.contrib.auth import get_user_model; User = get_user_model(); user = User.objects.get(username='"'"'{% raw %}{{ USERNAME }}{% endraw %}'"'"'); user.set_password('"'"'{% raw %}{{ PASSWORD }}{% endraw %}'"'"'); user.save()" | python manage.py shell'

# ----------------------------------------------------------------------
# DOCS
# ----------------------------------------------------------------------

_cog:
    cog -r docs/just.md

graph:
    just manage graph_models users \
        --exclude-models AbstractUser \
        --group-models \
        --output ./docs/applications/images/users.svg

docs-lock *ARGS:
    python -m uv pip compile {% raw %}{{ ARGS }}{% endraw %} --generate-hashes docs/requirements.in --output-file docs/requirements.txt

docs-upgrade:
    @just docs-lock --upgrade

docs-install:
    python -m uv pip install --upgrade -r docs/requirements.txt

docs-serve:
    #!/usr/bin/env sh
    just _cog
    if [ -f "/.dockerenv" ]; then
        sphinx-autobuild docs docs/_build/html --host "0.0.0.0"
    else
        sphinx-autobuild docs docs/_build/html --host "localhost"
    fi

docs-build LOCATION="docs/_build/html":
    just _cog
    sphinx-build docs {% raw %}{{ LOCATION }}{% endraw %}

# ----------------------------------------------------------------------
# DOCKER
# ----------------------------------------------------------------------

# Build services using docker-compose
build *ARGS:
    docker compose build {% raw %}{{ ARGS }}{% endraw %}

# Build production stack using docker-compose
build-prod:
    docker compose -f docker-compose.yml -f docker-compose.prod.yml build

# Stop and remove all containers, networks, images, and volumes
clean:
    @just down --volumes --rmi local

# Run the Playwright codegen command within the 'app' container
codegen *ARGS:
{%- if include_vite %}
    docker compose run --rm --no-deps -e DJANGO_VITE_DEV_SERVER_HOST=node app /bin/bash -c "python manage.py runserver 0.0.0.0:8000 & while ! curl -s http://0.0.0.0:8000 > /dev/null; do sleep 1; done; playwright codegen {% raw %}{{ ARGS }}{% endraw %}; kill %1"
{%- else %}
    @just command "python manage.py runserver 0.0.0.0:8000 & while ! curl -s http://0.0.0.0:8000 > /dev/null; do sleep 1; done; playwright codegen {% raw %}{{ ARGS }}{% endraw %}; kill %1"
{%- endif %}

# Run a command within the 'app' container
command *ARGS:
    docker compose run --rm --no-deps app /bin/bash -c "{% raw %}{{ ARGS }}{% endraw %}"

# Open an interactive shell within the 'app' container opens a console
console:
    docker compose run --rm --no-deps app /bin/bash

# Stop and remove all containers defined in docker-compose
down *ARGS:
    docker compose down {% raw %}{{ ARGS }}{% endraw %}

# Display the logs for containers, optionally using provided arguments (e.g., --follow)
logs *ARGS:
    docker compose logs {% raw %}{{ ARGS }}{% endraw %}

# Display the running containers and their statuses
ps:
    docker compose ps

# Pull the latest versions of all images defined in docker-compose
pull:
    docker compose pull

# Restart services, optionally targeting specific ones
restart *ARGS:
    docker compose restart {% raw %}{{ ARGS }}{% endraw %}

# Open an interactive shell within a specified container (default: 'app')
shell *ARGS="app":
    docker compose run --rm --no-deps {% raw %}{{ ARGS }}{% endraw %} /bin/bash

# Open a psql shell within the 'db' container
shell-db:
    docker compose run --rm --no-deps db psql -d {% raw %}{{ DATABASE_URL }}{% endraw %}

# Start services using docker-compose, defaulting to detached mode
start *ARGS="--detach":
    @just up {% raw %}{{ ARGS }}{% endraw %}

# Start the full production stack using docker-compose, defaulting to detached mode
start-prod *ARGS="--detach":
    @just up-prod {% raw %}{{ ARGS }}{% endraw %}

# Stop services by calling the 'down' command
stop:
    @just down

# Continuously display the latest logs by using the --follow option, optionally targeting specific containers
tail *ARGS:
    @just logs '--follow {% raw %}{{ ARGS }}{% endraw %}'

# Run tests using pytest within the 'app' container, with optional arguments
@test *ARGS:
{%- if include_vite %}
    docker compose run --rm --no-deps -e DJANGO_VITE_DEV_SERVER_HOST=node app pytest {% raw %}{{ ARGS }}{% endraw %}
{%- else %}
    @just command "pytest {% raw %}{{ ARGS }}{% endraw %}"
{%- endif %}

# Run tests with Playwright debug mode enabled, in the 'app' container, with optional arguments
@test-debug *ARGS:
{%- if include_vite %}
    docker compose run --rm --no-deps -e DJANGO_VITE_DEV_SERVER_HOST=node -e PWDEBUG=1 app pytest {% raw %}{{ ARGS }}{% endraw %}
{%- else %}
    docker compose run --rm --no-deps -e PWDEBUG=1 app pytest {% raw %}{{ ARGS }}{% endraw %}
{%- endif %}

# Start services using docker-compose, with optional arguments
up *ARGS:
    docker compose up {% raw %}{{ ARGS }}{% endraw %}

# Start the full production stack using docker-compose
up-prod *ARGS:
    docker compose -f docker-compose.yml -f docker-compose.prod.yml up {% raw %}{{ ARGS }}{% endraw %}


# ----------------------------------------------------------------------
# POSTGRES BACKUP AND RESTORE
# ----------------------------------------------------------------------

# dump our local database to file
pg_dump database_url=DATABASE_URL file='db.dump':
    docker compose run \
        --rm \
        --no-deps \
        db \
        pg_dump \
            --dbname {% raw %}{{ database_url }}{% endraw %} \
            --file /app/{% raw %}{{ file }}{% endraw %} \
            --format=c \
            --verbose

# dump our production database to file
pg_dump_prod file='production.dump':
    set PROD_DATABASE_URL := "{% raw %}{{ env_var('PROD_DATABASE_URL') }}{% endraw %}"
    @just pg_dump ${PROD_DATABASE_URL} {% raw %}{{ file }}{% endraw %}

# restore database backup to our local database
pg_restore file='db.dump':
    docker compose run \
        --rm \
        --no-deps \
        db \
        pg_restore \
            --clean \
            --dbname {% raw %}{{ DATABASE_URL }}{% endraw %} \
            --if-exists \
            --no-owner \
            --verbose \
            /app/{% raw %}{{ file }}{% endraw %}

# ----------------------------------------------------------------------
# UTILS
# ----------------------------------------------------------------------

envsync:
    #!/usr/bin/env python
    from pathlib import Path

    envfile = Path('.env')
    envfile_example = Path('.env.example')

    if not envfile.exists():
        envfile.write_text(envfile_example.read_text())

    with envfile.open() as f:
        lines = [line for line in f.readlines() if not line.endswith('# envsync: ignore\n')]
        lines = [line.split('=')[0] + '=\n' if line.endswith('# envsync: no-value\n') else line for line in lines]

        lines.sort()
        envfile_example.write_text(''.join(lines))

# format justfile
fmt:
    just --fmt --unstable

# run pre-commit on all files
lint:
    pre-commit run --all-files

# ----------------------------------------------------------------------
# COPIER
# ----------------------------------------------------------------------

# create a copier answers file
copier-copy TEMPLATE_PATH DESTINATION_PATH=".":
    pipx run copier copy {% raw %}{{ TEMPLATE_PATH }}{% endraw %} {% raw %}{{ DESTINATION_PATH }}{% endraw %}

# update the project using a copier answers file
copier-update ANSWERS_FILE *ARGS:
    pipx run copier update --answers-file {% raw %}{{ ANSWERS_FILE }}{% endraw %} {% raw %}{{ ARGS }}{% endraw %}

# loop through all answers files and update the project using copier
@copier-update-all *ARGS:
    for file in `ls .copier-answers/`; do just copier-update .copier-answers/$file "{% raw %}{{ ARGS }}{% endraw %}"; done
